#!/usr/bin/env python3

import json
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any


def main():
    print("=== Starting data processor ===")

    # ÐŸÐ¾Ð»ÑƒÑ‡Ð°ÐµÐ¼ Ð¿Ð°Ñ€Ð°Ð¼ÐµÑ‚Ñ€ Ð´Ð½ÐµÐ¹ Ð¸Ð· Ð°Ñ€Ð³ÑƒÐ¼ÐµÐ½Ñ‚Ð¾Ð² ÐºÐ¾Ð¼Ð°Ð½Ð´Ð½Ð¾Ð¹ ÑÑ‚Ñ€Ð¾ÐºÐ¸
    days = 30  # Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÑƒÐ¼Ð¾Ð»Ñ‡Ð°Ð½Ð¸ÑŽ
    if len(sys.argv) > 1:
        try:
            days = int(sys.argv[1])
            print(f"Using custom time range: last {days} days")
        except ValueError:
            print(f"Invalid days parameter: {sys.argv[1]}, using default: {days} days")

    # ÐŸÑƒÑ‚Ð¸
    script_dir = Path(__file__).parent
    repo_root = script_dir.parent
    data_path = repo_root / 'data/fio/librawstor'
    output_path = repo_root / 'docs/fio/librawstor/dashboard/data.json'

    print(f"Data path: {data_path}")
    print(f"Output path: {output_path}")
    print(f"Time range: last {days} days")

    if not data_path.exists():
        print("âŒ Data path does not exist!")
        return

    # Ð Ð°ÑÑÑ‡Ð¸Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ Ð´Ð°Ñ‚Ñƒ N Ð´Ð½ÐµÐ¹ Ð½Ð°Ð·Ð°Ð´
    cutoff_date = datetime.now() - timedelta(days=days)
    print(f"ðŸ“… Filtering data since: {cutoff_date.strftime('%Y-%m-%d')}")

    # Ð¡Ð¾Ð·Ð´Ð°ÐµÐ¼ Ð´Ð¸Ñ€ÐµÐºÑ‚Ð¾Ñ€Ð¸ÑŽ Ð´Ð»Ñ Ð²Ñ‹Ñ…Ð¾Ð´Ð½Ñ‹Ñ… Ð´Ð°Ð½Ð½Ñ‹Ñ…
    output_path.parent.mkdir(parents=True, exist_ok=True)

    try:
        # ÐžÐ±Ñ€Ð°Ð±Ð°Ñ‚Ñ‹Ð²Ð°ÐµÐ¼ ÑÑ‹Ñ€Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        all_test_results = collect_raw_data(data_path, cutoff_date)
        print(f"âœ… Collected {len(all_test_results)} test results from last {days} days")

        if not all_test_results:
            print("âš ï¸ No data found for the specified period. Using all available data.")
            all_test_results = collect_raw_data(data_path, None)
            days = 0  # ÐŸÐ¾Ð¼ÐµÑ‡Ð°ÐµÐ¼ Ñ‡Ñ‚Ð¾ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€ Ð½Ðµ Ð¿Ñ€Ð¸Ð¼ÐµÐ½ÐµÐ½

        # Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÐ¼ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²
        charts_data = prepare_charts_data(all_test_results)

        # Ð¤Ð¾Ñ€Ð¼Ð¸Ñ€ÑƒÐµÐ¼ Ð¸Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ JSON
        output = {
            "generated_at": datetime.utcnow().isoformat() + "Z",
            "filter": {
                "days": days,
                "cutoff_date": cutoff_date.isoformat() + "Z",
                "applied": days > 0 and len(all_test_results) > 0
            },
            "charts": charts_data,
            "summary": get_summary(all_test_results, charts_data, cutoff_date)
        }

        # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        with output_path.open('w', encoding='utf-8') as f:
            json.dump(output, f, indent=2, ensure_ascii=False)

        print(f"âœ… data.json successfully created for {days} days")
        print_summary(output['summary'])

    except Exception as e:
        print(f"âŒ Error: {e}")
        import traceback
        traceback.print_exc()


def parse_timestamp(timestamp_str: str) -> datetime:
    """ÐŸÐ°Ñ€ÑÐ¸Ñ‚ timestamp Ð¸Ð· Ñ€Ð°Ð·Ð»Ð¸Ñ‡Ð½Ñ‹Ñ… Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ð¾Ð²"""
    if not timestamp_str:
        return None

    # Ð£Ð´Ð°Ð»ÑÐµÐ¼ Ð»Ð¸ÑˆÐ½Ð¸Ðµ Ð¿Ñ€Ð¾Ð±ÐµÐ»Ñ‹
    timestamp_str = timestamp_str.strip()

    # ÐŸÑ€ÐµÐ¾Ð±Ñ€Ð°Ð·ÑƒÐµÐ¼ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð¾Ð½Ð¾Ð¹ Ð² Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚ Ð±ÐµÐ· Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð¾Ð½Ñ‹
    if '+' in timestamp_str:
        # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚: 2025-08-18T21:04:40+00:00
        timestamp_str = timestamp_str.split('+')[0]  # Ð‘ÐµÑ€ÐµÐ¼ Ñ‡Ð°ÑÑ‚ÑŒ Ð´Ð¾ +
    elif '-' in timestamp_str and 'T' in timestamp_str:
        # Ð¤Ð¾Ñ€Ð¼Ð°Ñ‚ Ñ Ð¾Ñ‚Ñ€Ð¸Ñ†Ð°Ñ‚ÐµÐ»ÑŒÐ½Ð¾Ð¹ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð¾Ð½Ð¾Ð¹: 2025-08-18T21:04:40-05:00
        parts = timestamp_str.rsplit('-', 1)
        if len(parts) == 2 and ':' in parts[1]:
            timestamp_str = parts[0]  # Ð‘ÐµÑ€ÐµÐ¼ Ñ‡Ð°ÑÑ‚ÑŒ Ð´Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð·Ð¾Ð½Ñ‹

    # Ð£Ð±Ð¸Ñ€Ð°ÐµÐ¼ Z ÐµÑÐ»Ð¸ ÐµÑÑ‚ÑŒ
    timestamp_str = timestamp_str.rstrip('Z')

    # ÐŸÐ¾Ð¿Ñ€Ð¾Ð±ÑƒÐµÐ¼ Ñ€Ð°Ð·Ð½Ñ‹Ðµ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñ‹ Ð´Ð°Ñ‚
    formats = [
        '%Y-%m-%dT%H:%M:%S.%f',  # ISO Ñ Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÐºÑƒÐ½Ð´Ð°Ð¼Ð¸
        '%Y-%m-%dT%H:%M:%S',  # ISO Ð±ÐµÐ· Ð¼Ð¸ÐºÑ€Ð¾ÑÐµÐºÑƒÐ½Ð´
        '%Y-%m-%d %H:%M:%S',  # ÐŸÑ€Ð¾ÑÑ‚Ð¾Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
        '%Y-%m-%d',  # Ð¢Ð¾Ð»ÑŒÐºÐ¾ Ð´Ð°Ñ‚Ð°
    ]

    for fmt in formats:
        try:
            return datetime.strptime(timestamp_str, fmt)
        except ValueError:
            continue

    print(f"âš ï¸ Could not parse timestamp: {timestamp_str}")
    return None


def is_recent(timestamp: datetime, cutoff_date: datetime) -> bool:
    """ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÑ‚, ÑÐ²Ð»ÑÐµÑ‚ÑÑ Ð»Ð¸ timestamp Ð½Ðµ ÑÑ‚Ð°Ñ€ÑˆÐµ cutoff_date"""
    if not timestamp or not cutoff_date:
        return True  # Ð•ÑÐ»Ð¸ Ð½ÐµÑ‚ Ð´Ð°Ñ‚Ñ‹, Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼ Ð² Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
    return timestamp >= cutoff_date


def collect_raw_data(data_path: Path, cutoff_date: datetime) -> List[Dict[str, Any]]:
    """Ð¡Ð¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ ÑÑ‹Ñ€Ñ‹Ðµ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ñ Ñ„Ð¸Ð»ÑŒÑ‚Ñ€Ð°Ñ†Ð¸ÐµÐ¹ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸"""
    all_results = []
    skipped_old = 0
    skipped_no_date = 0
    
    for config_dir in data_path.iterdir():
        if not config_dir.is_dir():
            continue
            
        config_name = config_dir.name
        print(f"Processing configuration: {config_name}")
        
        for json_file in config_dir.glob('*.json'):
            try:
                commit_sha = json_file.stem
                meta_file = json_file.with_suffix('.meta')
                
                # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ JSON Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð°Ð¼Ð¸ Ñ‚ÐµÑÑ‚Ð°
                test_data = json.loads(json_file.read_text(encoding='utf-8'))
                
                # Ð§Ð¸Ñ‚Ð°ÐµÐ¼ META Ñ„Ð°Ð¹Ð»
                meta_data = {}
                if meta_file.exists():
                    meta_data = json.loads(meta_file.read_text(encoding='utf-8'))
                
                # ÐŸÐ°Ñ€ÑÐ¸Ð¼ timestamp
                timestamp_str = meta_data.get('date', '')
                timestamp = parse_timestamp(timestamp_str)
                
                # Ð¤Ð¸Ð»ÑŒÑ‚Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
                if not is_recent(timestamp, cutoff_date):
                    skipped_old += 1
                    continue
                
                if not timestamp:
                    skipped_no_date += 1
                    # Ð ÐµÑˆÐ°ÐµÐ¼ Ð²ÐºÐ»ÑŽÑ‡Ð°Ñ‚ÑŒ Ð»Ð¸ Ñ‚ÐµÑÑ‚Ñ‹ Ð±ÐµÐ· Ð´Ð°Ñ‚Ñ‹
                    # ÐŸÐ¾ÐºÐ° Ð²ÐºÐ»ÑŽÑ‡Ð°ÐµÐ¼, Ð½Ð¾ Ð¿Ð¾Ð¼ÐµÑ‡Ð°ÐµÐ¼
                    timestamp_str = "Unknown date"
                
                # Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÐ¼ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸
                metrics = extract_fio_metrics(test_data)
                
                if metrics:
                    test_result = {
                        'config': config_name,
                        'commit_sha': commit_sha,
                        'timestamp': timestamp.isoformat() + 'Z' if timestamp else timestamp_str,
                        'timestamp_obj': timestamp,  # Ð¡Ð¾Ñ…Ñ€Ð°Ð½ÑÐµÐ¼ Ð¾Ð±ÑŠÐµÐºÑ‚ Ð´Ð»Ñ ÑÐ¾Ñ€Ñ‚Ð¸Ñ€Ð¾Ð²ÐºÐ¸
                        'branch': meta_data.get('branch', 'unknown'),
                        'test_url': f"../{config_name}/{commit_sha}",
                        **metrics
                    }
                    all_results.append(test_result)
                    
            except Exception as e:
                print(f"  âŒ Error processing {json_file.name}: {e}")
    
    if skipped_old > 0:
        print(f"ðŸ“… Skipped {skipped_old} tests older than cutoff date")
    if skipped_no_date > 0:
        print(f"â° Skipped {skipped_no_date} tests without date")
    
    return all_results


def extract_fio_metrics(test_data: Dict) -> Dict[str, float]:
    """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ð¼ÐµÑ‚Ñ€Ð¸ÐºÐ¸ IOPS Ð¸ Latency Ð¸Ð· Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² FIO"""
    metrics = {}
    
    try:
        if 'jobs' in test_data and len(test_data['jobs']) > 0:
            job = test_data['jobs'][0]
            
            # IOPS metrics
            if 'read' in job and 'iops' in job['read']:
                metrics['iops_read'] = float(job['read']['iops'])
            if 'write' in job and 'iops' in job['write']:
                metrics['iops_write'] = float(job['write']['iops'])
            
            # Latency metrics
            if 'read' in job and 'lat_ns' in job['read'] and 'mean' in job['read']['lat_ns']:
                metrics['latency_read'] = float(job['read']['lat_ns']['mean']) / 1_000_000
            if 'write' in job and 'lat_ns' in job['write'] and 'mean' in job['write']['lat_ns']:
                metrics['latency_write'] = float(job['write']['lat_ns']['mean']) / 1_000_000
            
            # ÐÐ»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð¿ÑƒÑ‚Ð¸ Ðº latency
            if 'latency_read' not in metrics and 'read' in job and 'lat' in job['read'] and 'mean' in job['read']['lat']:
                metrics['latency_read'] = float(job['read']['lat']['mean']) / 1000
            if 'latency_write' not in metrics and 'write' in job and 'lat' in job['write'] and 'mean' in job['write']['lat']:
                metrics['latency_write'] = float(job['write']['lat']['mean']) / 1000
                
    except Exception as e:
        print(f"    âš ï¸ Could not extract metrics: {e}")
    
    return metrics


def prepare_charts_data(all_results: List[Dict]) -> Dict[str, List[Dict]]:
    """ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð°Ð²Ð»Ð¸Ð²Ð°ÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð´Ð»Ñ 8 Ð³Ñ€Ð°Ñ„Ð¸ÐºÐ¾Ð²"""
    charts_data = {}
    
    # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
    sorted_results = sorted(
        [r for r in all_results if r.get('timestamp_obj')], 
        key=lambda x: x['timestamp_obj']
    )
    
    # Ð”Ð»Ñ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ð¾Ð² Ð±ÐµÐ· Ð´Ð°Ñ‚Ñ‹ Ð´Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð² ÐºÐ¾Ð½ÐµÑ†
    no_date_results = [r for r in all_results if not r.get('timestamp_obj')]
    sorted_results.extend(no_date_results)
    
    metrics = ['iops_read', 'iops_write', 'latency_read', 'latency_write']
    
    for metric in metrics:
        charts_data[f"{metric}_by_config"] = group_by_config(sorted_results, metric)
        charts_data[f"{metric}_by_branch"] = group_by_branch(sorted_results, metric)
    
    return charts_data


def group_by_config(all_results: List[Dict], metric: str) -> List[Dict]:
    """Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ ÐºÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸ÑÐ¼ Ñ‚ÐµÑÑ‚Ð¾Ð²"""
    valid_results = [r for r in all_results if metric in r and r[metric] is not None]
    
    config_groups = {}
    for result in valid_results:
        config = result['config']
        if config not in config_groups:
            config_groups[config] = []
        
        config_groups[config].append({
            'group': config,
            'timestamp': result['timestamp'],
            'value': result[metric],
            'commit_sha': result['commit_sha'],
            'branch': result['branch'],
            'test_url': result['test_url'],
            'config': config
        })

    chart_data = []
    for config, points in config_groups.items():
        # Ð¡Ð¾Ñ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð¿Ð¾ Ð²Ñ€ÐµÐ¼ÐµÐ½Ð¸
        sorted_points = sorted(
            points, 
            key=lambda x: x['timestamp'] if x['timestamp'] != "Unknown date" else "9999-12-31"
        )
        chart_data.extend(sorted_points)
    
    return chart_data


def group_by_branch(all_results: List[Dict], metric: str) -> List[Dict]:
    """Ð“Ñ€ÑƒÐ¿Ð¿Ð¸Ñ€ÑƒÐµÑ‚ Ð´Ð°Ð½Ð½Ñ‹Ðµ Ð¿Ð¾ Ð²ÐµÑ‚ÐºÐ°Ð¼"""
    valid_results = [r for r in all_results if metric in r and r[metric] is not None]
    
    branch_groups = {}
    for result in valid_results:
        branch = result['branch']
        if branch not in branch_groups:
            branch_groups[branch] = []
        
        branch_groups[branch].append({
            'group': branch,
            'timestamp': result['timestamp'],
            'value': result[metric],
            'commit_sha': result['commit_sha'],
            'config': result['config'],
            'test_url': result['test_url'],
            'branch': branch
        })
    
    chart_data = []
    for branch, points in branch_groups.items():
        sorted_points = sorted(
            points, 
            key=lambda x: x['timestamp'] if x['timestamp'] != "Unknown date" else "9999-12-31"
        )
        chart_data.extend(sorted_points)
    
    return chart_data


def get_summary(all_results: List[Dict], charts_data: Dict, cutoff_date: datetime) -> Dict[str, Any]:
    """Ð“ÐµÐ½ÐµÑ€Ð¸Ñ€ÑƒÐµÑ‚ summary Ð¸Ð½Ñ„Ð¾Ñ€Ð¼Ð°Ñ†Ð¸ÑŽ"""
    configs = set(r['config'] for r in all_results)
    branches = set(r['branch'] for r in all_results)
    
    # Ð’Ñ€ÐµÐ¼ÐµÐ½Ð½Ð¾Ð¹ Ð´Ð¸Ð°Ð¿Ð°Ð·Ð¾Ð½
    timestamps = [r['timestamp_obj'] for r in all_results if r.get('timestamp_obj')]
    time_range = {
        'start': min(timestamps).isoformat() + 'Z' if timestamps else None,
        'end': max(timestamps).isoformat() + 'Z' if timestamps else None
    }
    
    # Ð¢ÐµÑÑ‚Ñ‹ Ð±ÐµÐ· Ð´Ð°Ñ‚Ñ‹
    tests_without_date = len([r for r in all_results if not r.get('timestamp_obj')])
    
    chart_points = {chart: len(data) for chart, data in charts_data.items()}
    
    return {
        'total_tests': len(all_results),
        'tests_without_date': tests_without_date,
        'total_configurations': len(configs),
        'total_branches': len(branches),
        'configurations': sorted(list(configs)),
        'branches': sorted(list(branches)),
        'time_range': time_range,
        'cutoff_date': cutoff_date.isoformat() + 'Z',
        'chart_points': chart_points
    }


def print_summary(summary: Dict):
    """ÐŸÐµÑ‡Ð°Ñ‚Ð°ÐµÑ‚ ÐºÑ€Ð°ÑÐ¸Ð²Ñ‹Ð¹ summary"""
    print("\n=== SUMMARY ===")
    print(f"Total tests: {summary['total_tests']}")
    if summary['tests_without_date'] > 0:
        print(f"Tests without date: {summary['tests_without_date']}")
    print(f"Configurations: {summary['total_configurations']}")
    print(f"Branches: {summary['total_branches']}")
    
    if summary['time_range']['start']:
        start_date = datetime.fromisoformat(summary['time_range']['start'].replace('Z', ''))
        end_date = datetime.fromisoformat(summary['time_range']['end'].replace('Z', ''))
        cutoff_date = datetime.fromisoformat(summary['cutoff_date'].replace('Z', ''))
        
        print(f"Data range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}")
        print(f"Cutoff date: {cutoff_date.strftime('%Y-%m-%d')} (-30 days)")
    
    print("\nChart data points:")
    for chart, count in summary['chart_points'].items():
        print(f"  {chart}: {count} points")
    
    print(f"\nConfigurations: {', '.join(summary['configurations'])}")
    print(f"Branches: {', '.join(summary['branches'])}")


if __name__ == "__main__":
    main()
